{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding and Predicting Property Maintenance Fines\n",
    "\n",
    "This machine learning exercise is based on a data challenge from the Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)). \n",
    "\n",
    "The Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)) and the Michigan Student Symposium for Interdisciplinary Statistical Sciences ([MSSISS](https://sites.lsa.umich.edu/mssiss/)) have partnered with the City of Detroit to help solve one of the most pressing problems facing Detroit - blight. [Blight violations](http://www.detroitmi.gov/How-Do-I/Report/Blight-Complaint-FAQs) are issued by the city to individuals who allow their properties to remain in a deteriorated condition. Every year, the city of Detroit issues millions of dollars in fines to residents and every year, many of these fines remain unpaid. Enforcing unpaid blight fines is a costly and tedious process, so the city wants to know: how can we increase blight ticket compliance?\n",
    "\n",
    "The first step in answering this question is understanding when and why a resident might fail to comply with a blight ticket. This is where predictive modeling comes in. For this assignment, your task is to predict whether a given blight ticket will be paid on time.\n",
    "\n",
    "All data has been provided through the [Detroit Open Data Portal](https://data.detroitmi.gov/).\n",
    "\n",
    "<br>\n",
    "\n",
    "**File descriptions**\n",
    "\n",
    "    train.csv - the training set (all tickets issued 2004-2011)\n",
    "    test.csv - the test set (all tickets issued 2012-2016)\n",
    "    addresses.csv & latlons.csv - mapping from ticket id to addresses, and from addresses to lat/lon coordinates. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv\n",
    "\n",
    "    ticket_id - unique identifier for tickets\n",
    "    agency_name - Agency that issued the ticket\n",
    "    inspector_name - Name of inspector that issued the ticket\n",
    "    violator_name - Name of the person/organization that the ticket was issued to\n",
    "    violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "    mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "    ticket_issued_date - Date and time the ticket was issued\n",
    "    hearing_date - Date and time the violator's hearing was scheduled\n",
    "    violation_code, violation_description - Type of violation\n",
    "    disposition - Judgment and judgement type\n",
    "    fine_amount - Violation fine amount, excluding fees\n",
    "    admin_fee - $20 fee assigned to responsible judgments\n",
    "state_fee - $10 fee assigned to responsible judgments\n",
    "    late_fee - 10% fee assigned to responsible judgments\n",
    "    discount_amount - discount applied, if any\n",
    "    clean_up_cost - DPW clean-up or graffiti removal cost\n",
    "    judgment_amount - Sum of all fines and fees\n",
    "    grafitti_status - Flag for graffiti violations\n",
    "    \n",
    "train.csv only\n",
    "\n",
    "    payment_amount - Amount paid, if any\n",
    "    payment_date - Date payment was made, if it was received\n",
    "    payment_status - Current payment status as of Feb 1 2017\n",
    "    balance_due - Fines and fees still owed\n",
    "    collection_status - Flag for payments in collections\n",
    "    compliance [target variable for prediction] \n",
    "     Null = Not responsible\n",
    "     0 = Responsible, non-compliant\n",
    "     1 = Responsible, compliant\n",
    "    compliance_detail - More information on why each ticket was marked compliant or non-compliant\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "**Objectives of analysis:**\n",
    "\n",
    "1. Predict the probability that the corresponding blight ticket will be paid on time, prediction is evaluated by Area Under the ROC Curve (AUC). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "\n",
    "\n",
    "def blight_model():\n",
    "    \n",
    "    # Read data into pandas dataframe with the encoding 'ISO-8859-1'\n",
    "    df_learn = pd.read_csv('train.csv', encoding = 'ISO-8859-1')\n",
    "    df_test = pd.read_csv('test.csv', encoding = 'ISO-8859-1')\n",
    "    address = pd.read_csv('addresses.csv', encoding = 'ISO-8859-1')\n",
    "    location = pd.read_csv('latlons.csv', encoding = 'ISO-8859-1')\n",
    "\n",
    "    # Merge train data with address by ticket ids, then merge with location by address\n",
    "    joined_ad = pd.merge(df_learn, address, how = 'inner', left_on='ticket_id', right_on='ticket_id')\n",
    "    joined_cor = pd.merge(joined_ad, location, how = 'inner', left_on = 'address', right_on = 'address')\n",
    "\n",
    "    # Merge test data with address by ticket ids, then merge with location by address\n",
    "    joined_test_ad = pd.merge(df_test, address, how = 'inner', left_on='ticket_id', right_on='ticket_id')\n",
    "    joined_test_cor = pd.merge(joined_test_ad, location, how = 'inner', left_on = 'address', right_on = 'address')\n",
    "    \n",
    "    # Find distance based on Euclidean distance formula\n",
    "    def great_circle_distance(x):\n",
    "        r = 6371\n",
    "        a = math.radians(0)\n",
    "        b = math.radians(0)\n",
    "        ChangeLat = math.radians(x['lat'] - 0)\n",
    "        ChangeLon = math.radians(x['lon'] - 0)\n",
    "\n",
    "        c = math.sin(ChangeLat/2)*math.sin(ChangeLat/2) + math.cos(a)*math.cos(b)*math.sin(ChangeLon/2)*math.sin(ChangeLon/2)\n",
    "        d = 2 * math.atan2(math.sqrt(c), math.sqrt(1-c))\n",
    "        e = r * d\n",
    "        return e\n",
    "    \n",
    "    # Select useful variables to the model\n",
    "    target_ft = ['ticket_id', 'state', 'agency_name', 'disposition', 'violation_code', 'ticket_issued_date', 'hearing_date', \n",
    "                 'discount_amount', 'late_fee',\n",
    "                 'judgment_amount', 'compliance', 'lat', 'lon']\n",
    "    \n",
    "    # Set explanatory variables to all columns but ticket ids\n",
    "    learn = joined_cor[target_ft[1:]]\n",
    "    \n",
    "    # Remove missing data and fill nans\n",
    "    learn = learn[~learn['compliance'].isnull()]\n",
    "    learn.fillna(-10000, inplace=True)\n",
    "    \n",
    "    # Find difference btween issue date and hearing data\n",
    "    learn['ticket_issued_date'] = pd.to_datetime(learn['ticket_issued_date'])\n",
    "    learn['hearing_date'] = pd.to_datetime(learn['hearing_date'])\n",
    "    learn['diff'] = learn['hearing_date'] - learn['ticket_issued_date']\n",
    "    learn.drop(['ticket_issued_date', 'hearing_date'], axis = 1, inplace=True)\n",
    "    learn['diff'] = learn['diff'].dt.days.astype(float)\n",
    "    \n",
    "    # Leave only Michigan ticket holders\n",
    "    learn['state'] = learn['state'] == 'MI'    \n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    # Convert categorical variables using label encoder\n",
    "    for i in ['agency_name','disposition', 'violation_code']:\n",
    "        learn[i] = le.fit_transform(learn[i])\n",
    "\n",
    "    target_ft.pop(-3)\n",
    "    \n",
    "    # Process test dataset the same way as train dataset\n",
    "    test = joined_test_cor[target_ft[1:]]\n",
    "    test.fillna(-10000, inplace=True)\n",
    "\n",
    "    test['ticket_issued_date'] = pd.to_datetime(test['ticket_issued_date'])\n",
    "    test['hearing_date'] = pd.to_datetime(test['hearing_date'])\n",
    "    test['diff'] = test['hearing_date'] - test['ticket_issued_date']\n",
    "    test.drop(['ticket_issued_date', 'hearing_date'], axis = 1, inplace=True)\n",
    "    test['diff'] = test['diff'].dt.days.astype(float)\n",
    "    test['state'] = test['state'] == 'MI'\n",
    "    \n",
    "\n",
    "    for i in ['agency_name','disposition', 'violation_code']:\n",
    "        test[i] = le.fit_transform(test[i])\n",
    "\n",
    "    X_learn = learn.loc[:, learn.columns != 'compliance']\n",
    "    y_learn = learn['compliance']\n",
    "    \n",
    "    # Perform train / test split on train dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_learn, y_learn, random_state=0)\n",
    "    \n",
    "    # Use gradient boosting as the classifier\n",
    "    clf = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probability based on X_test\n",
    "    X_result = clf.predict_proba(X_test)\n",
    "\n",
    "    f_X, t_X, e_X = roc_curve(y_test, X_result[:, -1])\n",
    "    roc_aucX = auc(f_X, t_X)\n",
    "\n",
    "    # Predict probability based on test dataset\n",
    "    R_result = clf.predict_proba(test)\n",
    "\n",
    "    output = pd.DataFrame(R_result, joined_test_cor['ticket_id'], columns=['0', 'compliance'])\n",
    "    output = output['compliance']\n",
    "    output.reindex(df_test['ticket_id'])\n",
    "\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "nNS8l",
   "launcher_item_id": "yWWk7",
   "part_id": "w8BSS"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
